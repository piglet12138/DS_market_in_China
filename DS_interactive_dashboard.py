import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®åˆ†æå¸ˆå²—ä½ç»¼åˆåˆ†æçœ‹æ¿",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
    try:
        # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼
        encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig', 'latin1']
        df = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv('DS_raw.csv', encoding=encoding)
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸè¯»å–åˆ°æ•°æ®
                if len(df) > 0 and len(df.columns) > 0:
                    break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                st.warning(f"ä½¿ç”¨ {encoding} ç¼–ç æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if df is None or len(df) == 0:
            st.error("æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç¼–ç ")
            return None
        
        # æ˜¾ç¤ºåŸå§‹åˆ—å
        
        
        # ç›´æ¥ä½¿ç”¨æˆåŠŸåŠ è½½çš„æ•°æ®ï¼Œè·³è¿‡ç¼–ç æ£€æµ‹
        
        
        # æ ‡å‡†åŒ–åˆ—å
        column_mapping = {}
        for col in df.columns:
            col_lower = col.lower()
            if 'è¡Œä¸š' in col or 'industry' in col_lower:
                column_mapping[col] = 'è¡Œä¸š'
            elif 'å²—ä½' in col or 'position' in col_lower or 'job' in col_lower:
                column_mapping[col] = 'å²—ä½'
            elif 'å…¬å¸' in col and 'åç§°' in col:
                column_mapping[col] = 'å…¬å¸åç§°'
            elif 'å…¬å¸' in col and 'ä¸»å' in col:
                column_mapping[col] = 'å…¬å¸ä¸»å'
            elif 'å‘˜å·¥' in col and 'äººæ•°' in col:
                column_mapping[col] = 'å‘˜å·¥äººæ•°'
            elif 'æ”¶å…¥' in col and 'å¹´' in col:
                column_mapping[col] = 'å¹³å‡å¹´æ”¶å…¥'
            elif 'åœ¨èŒ' in col and 'äººæ•°' in col:
                column_mapping[col] = 'åœ¨èŒäººæ•°'
            elif 'åœ¨èŒ' in col and 'å¤©æ•°' in col:
                column_mapping[col] = 'å¹³å‡åœ¨èŒå¤©æ•°'
            elif 'å¤´è…°å°¾' in col:
                column_mapping[col] = 'å¤´è…°å°¾'
            elif 'åŸå¸‚' in col or 'city' in col_lower:
                column_mapping[col] = 'åŸå¸‚'
            elif 'è§„æ¨¡' in col:
                column_mapping[col] = 'è§„æ¨¡'
            elif 'ä¼ä¸š' in col and 'æ€§è´¨' in col:
                column_mapping[col] = 'ä¼ä¸šæ€§è´¨'
            elif 'æˆç«‹' in col and 'æ—¥æœŸ' in col:
                column_mapping[col] = 'æˆç«‹æ—¥æœŸ'
            elif 'å·¥ä½œ' in col and 'æ•°' in col:
                column_mapping[col] = 'å¹³å‡å·¥ä½œæ•°'
            elif 'å·¥å•†' in col and 'ç±»å‹' in col:
                column_mapping[col] = 'ä¼ä¸šå·¥å•†ç±»å‹'
        
        # åº”ç”¨åˆ—åæ˜ å°„
        if column_mapping:
            df = df.rename(columns=column_mapping)
            
        
        # æ˜¾ç¤ºå¤„ç†åçš„åˆ—å
        
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['å²—ä½', 'è¡Œä¸š']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            st.error(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
            st.info("å¯ç”¨åˆ—: " + ", ".join(df.columns.tolist()))
            return None
        
        return df
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None

def detect_and_remove_outliers(df, column, method='iqr', multiplier=1.5, remove_outliers=True):
    """æ£€æµ‹å’Œç§»é™¤å¼‚å¸¸å€¼"""
    if column not in df.columns:
        return df
    
    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
    df[column] = pd.to_numeric(df[column], errors='coerce')
    
    # ç§»é™¤0å€¼å’Œè´Ÿå€¼
    df = df[df[column] > 0]
    
    # å¦‚æœä¸è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†ï¼Œç›´æ¥è¿”å›
    if not remove_outliers:
        return df
    
    if method == 'iqr':
        # IQRæ–¹æ³•
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - multiplier * IQR
        upper_bound = Q3 + multiplier * IQR
        df_clean = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    elif method == 'zscore':
        # Z-scoreæ–¹æ³•
        z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())
        df_clean = df[z_scores < multiplier]
    else:
        df_clean = df
    
    return df_clean

def filter_ds_jobs(df):
    """ç­›é€‰æ•°æ®åˆ†æå¸ˆç›¸å…³å²—ä½"""
    ds_keywords = ['æ•°æ®åˆ†æ', 'æ•°æ®æŒ–æ˜', 'æ•°æ®ç§‘å­¦', 'å•†ä¸šåˆ†æ', 'BI', 'æ•°æ®è¿è¥', 'æ•°æ®å·¥ç¨‹å¸ˆ']
    ds_mask = df['å²—ä½'].str.contains('|'.join(ds_keywords), na=False, case=False)
    return df[ds_mask].copy()

def create_salary_analysis(df_filtered, remove_outliers=True):
    """è–ªèµ„åˆ†æ"""
    if remove_outliers:
        df_salary = detect_and_remove_outliers(df_filtered, 'å¹³å‡å¹´æ”¶å…¥', remove_outliers=True)
    else:
        df_salary = detect_and_remove_outliers(df_filtered, 'å¹³å‡å¹´æ”¶å…¥', remove_outliers=False)
    
    if len(df_salary) == 0:
        return None, "æ²¡æœ‰æœ‰æ•ˆçš„è–ªèµ„æ•°æ®"
    
    # è–ªèµ„åˆ†å¸ƒå›¾
    fig1 = px.histogram(
        df_salary, 
        x='å¹³å‡å¹´æ”¶å…¥', 
        nbins=30,
        title='è–ªèµ„åˆ†å¸ƒç›´æ–¹å›¾',
        labels={'å¹³å‡å¹´æ”¶å…¥': 'å¹³å‡å¹´æ”¶å…¥ï¼ˆå…ƒï¼‰', 'count': 'é¢‘æ¬¡'}
    )
    fig1.add_vline(x=df_salary['å¹³å‡å¹´æ”¶å…¥'].mean(), line_dash="dash", line_color="red",
                   annotation_text=f"å¹³å‡å€¼: {df_salary['å¹³å‡å¹´æ”¶å…¥'].mean():.1f}")
    
    # å„è¡Œä¸šå¹³å‡è–ªèµ„
    industry_salary = df_salary.groupby('è¡Œä¸š')['å¹³å‡å¹´æ”¶å…¥'].agg(['mean', 'count']).reset_index()
    industry_salary = industry_salary[industry_salary['count'] >= 3].sort_values('mean', ascending=False)
    
    fig2 = px.bar(
        industry_salary, 
        x='è¡Œä¸š', 
        y='mean',
        title='å„è¡Œä¸šå¹³å‡è–ªèµ„',
        labels={'mean': 'å¹³å‡å¹´æ”¶å…¥ï¼ˆå…ƒï¼‰'},
        color='mean',
        color_continuous_scale='viridis'
    )
    fig2.update_xaxes(tickangle=45)
    
    # è–ªèµ„ç®±çº¿å›¾
    fig3 = px.box(
        df_salary, 
        y='å¹³å‡å¹´æ”¶å…¥',
        title='è–ªèµ„ç®±çº¿å›¾',
        labels={'å¹³å‡å¹´æ”¶å…¥': 'å¹³å‡å¹´æ”¶å…¥ï¼ˆå…ƒï¼‰'}
    )
    
    return {
        'fig1': fig1,
        'fig2': fig2,
        'fig3': fig3,
        'stats': {
            'count': len(df_salary),
            'mean': df_salary['å¹³å‡å¹´æ”¶å…¥'].mean(),
            'median': df_salary['å¹³å‡å¹´æ”¶å…¥'].median(),
            'std': df_salary['å¹³å‡å¹´æ”¶å…¥'].std(),
            'min': df_salary['å¹³å‡å¹´æ”¶å…¥'].min(),
            'max': df_salary['å¹³å‡å¹´æ”¶å…¥'].max()
        }
    }, None

def create_job_distribution_analysis(df_filtered, remove_outliers=True):
    """å²—ä½åˆ†å¸ƒåˆ†æ"""
    if remove_outliers:
        df_jobs = detect_and_remove_outliers(df_filtered, 'åœ¨èŒäººæ•°', remove_outliers=True)
    else:
        df_jobs = detect_and_remove_outliers(df_filtered, 'åœ¨èŒäººæ•°', remove_outliers=False)
    
    if len(df_jobs) == 0:
        return None, "æ²¡æœ‰æœ‰æ•ˆçš„å²—ä½æ•°æ®"
    
    # å²—ä½äººæ•°åˆ†å¸ƒ
    fig1 = px.histogram(
        df_jobs, 
        x='åœ¨èŒäººæ•°', 
        nbins=30,
        title='å²—ä½äººæ•°åˆ†å¸ƒ',
        labels={'åœ¨èŒäººæ•°': 'åœ¨èŒäººæ•°', 'count': 'é¢‘æ¬¡'}
    )
    fig1.add_vline(x=df_jobs['åœ¨èŒäººæ•°'].mean(), line_dash="dash", line_color="red",
                   annotation_text=f"å¹³å‡å€¼: {df_jobs['åœ¨èŒäººæ•°'].mean():.1f}")
    
    # å„è¡Œä¸šå²—ä½äººæ•°
    industry_jobs = df_jobs.groupby('è¡Œä¸š')['åœ¨èŒäººæ•°'].agg(['sum', 'count']).reset_index()
    industry_jobs = industry_jobs[industry_jobs['count'] >= 3].sort_values('sum', ascending=False)
    
    fig2 = px.bar(
        industry_jobs, 
        x='è¡Œä¸š', 
        y='sum',
        title='å„è¡Œä¸šæ€»å²—ä½äººæ•°',
        labels={'sum': 'æ€»å²—ä½äººæ•°'},
        color='sum',
        color_continuous_scale='plasma'
    )
    fig2.update_xaxes(tickangle=45)
    
    # å¹³å‡å²—ä½äººæ•°
    avg_jobs = df_jobs.groupby('è¡Œä¸š')['åœ¨èŒäººæ•°'].mean().reset_index()
    avg_jobs = avg_jobs[avg_jobs['è¡Œä¸š'].isin(industry_jobs['è¡Œä¸š'])].sort_values('åœ¨èŒäººæ•°', ascending=False)
    
    fig3 = px.bar(
        avg_jobs, 
        x='è¡Œä¸š', 
        y='åœ¨èŒäººæ•°',
        title='å„è¡Œä¸šå¹³å‡å²—ä½äººæ•°',
        labels={'åœ¨èŒäººæ•°': 'å¹³å‡å²—ä½äººæ•°'},
        color='åœ¨èŒäººæ•°',
        color_continuous_scale='inferno'
    )
    fig3.update_xaxes(tickangle=45)
    
    return {
        'fig1': fig1,
        'fig2': fig2,
        'fig3': fig3,
        'stats': {
            'count': len(df_jobs),
            'total_jobs': df_jobs['åœ¨èŒäººæ•°'].sum(),
            'mean': df_jobs['åœ¨èŒäººæ•°'].mean(),
            'median': df_jobs['åœ¨èŒäººæ•°'].median(),
            'std': df_jobs['åœ¨èŒäººæ•°'].std()
        }
    }, None

def create_employee_ratio_analysis(df_filtered, remove_outliers=True):
    """å‘˜å·¥å æ¯”åˆ†æ"""
    # è®¡ç®—å æ¯”
    df_ratio = df_filtered.copy()
    df_ratio['åœ¨èŒäººæ•°'] = pd.to_numeric(df_ratio['åœ¨èŒäººæ•°'], errors='coerce')
    df_ratio['å‘˜å·¥äººæ•°'] = pd.to_numeric(df_ratio['å‘˜å·¥äººæ•°'], errors='coerce')
    
    valid_ratio = df_ratio[(df_ratio['åœ¨èŒäººæ•°'] > 0) & (df_ratio['å‘˜å·¥äººæ•°'] > 0)].copy()
    valid_ratio['DSå æ¯”'] = valid_ratio['åœ¨èŒäººæ•°'] / valid_ratio['å‘˜å·¥äººæ•°'] * 100
    
    if remove_outliers:
        valid_ratio = detect_and_remove_outliers(valid_ratio, 'DSå æ¯”', remove_outliers=True)
    else:
        valid_ratio = detect_and_remove_outliers(valid_ratio, 'DSå æ¯”', remove_outliers=False)
    
    if len(valid_ratio) == 0:
        return None, "æ²¡æœ‰æœ‰æ•ˆçš„å æ¯”æ•°æ®"
    
    # å æ¯”åˆ†å¸ƒ
    fig1 = px.histogram(
        valid_ratio, 
        x='DSå æ¯”', 
        nbins=30,
        title='æ•°æ®åˆ†æå¸ˆå æ¯”åˆ†å¸ƒ',
        labels={'DSå æ¯”': 'å æ¯”ï¼ˆ%ï¼‰', 'count': 'é¢‘æ¬¡'}
    )
    fig1.add_vline(x=valid_ratio['DSå æ¯”'].mean(), line_dash="dash", line_color="red",
                   annotation_text=f"å¹³å‡å€¼: {valid_ratio['DSå æ¯”'].mean():.3f}%")
    
    # å„è¡Œä¸šå¹³å‡å æ¯”
    industry_ratio = valid_ratio.groupby('è¡Œä¸š')['DSå æ¯”'].agg(['mean', 'count']).reset_index()
    industry_ratio = industry_ratio[industry_ratio['count'] >= 3].sort_values('mean', ascending=False)
    
    fig2 = px.bar(
        industry_ratio, 
        x='è¡Œä¸š', 
        y='mean',
        title='å„è¡Œä¸šå¹³å‡å æ¯”',
        labels={'mean': 'å¹³å‡å æ¯”ï¼ˆ%ï¼‰'},
        color='mean',
        color_continuous_scale='viridis'
    )
    fig2.update_xaxes(tickangle=45)
    
    # å æ¯”ä¸å…¬å¸è§„æ¨¡å…³ç³»
    fig3 = px.scatter(
        valid_ratio, 
        x='å‘˜å·¥äººæ•°', 
        y='DSå æ¯”',
        title='å æ¯”ä¸å…¬å¸è§„æ¨¡å…³ç³»',
        labels={'å‘˜å·¥äººæ•°': 'å‘˜å·¥äººæ•°', 'DSå æ¯”': 'å æ¯”ï¼ˆ%ï¼‰'},
        hover_data=['å…¬å¸åç§°', 'å²—ä½']
    )
    fig3.update_xaxes(type="log")
    
    return {
        'fig1': fig1,
        'fig2': fig2,
        'fig3': fig3,
        'stats': {
            'count': len(valid_ratio),
            'mean_ratio': valid_ratio['DSå æ¯”'].mean(),
            'median_ratio': valid_ratio['DSå æ¯”'].median(),
            'max_ratio': valid_ratio['DSå æ¯”'].max(),
            'min_ratio': valid_ratio['DSå æ¯”'].min()
        }
    }, None

def calculate_company_scores(df_filtered):
    """è®¡ç®—ä¼ä¸šç»¼åˆè¯„åˆ†"""
    if len(df_filtered) == 0:
        return None, "æ²¡æœ‰æœ‰æ•ˆæ•°æ®"
    
    # æ•°æ®é¢„å¤„ç†
    df = df_filtered.copy()
    df['å¹³å‡å¹´æ”¶å…¥'] = pd.to_numeric(df['å¹³å‡å¹´æ”¶å…¥'], errors='coerce')
    df['åœ¨èŒäººæ•°'] = pd.to_numeric(df['åœ¨èŒäººæ•°'], errors='coerce')
    df['å‘˜å·¥äººæ•°'] = pd.to_numeric(df['å‘˜å·¥äººæ•°'], errors='coerce')
    df['å¹³å‡åœ¨èŒå¤©æ•°'] = pd.to_numeric(df['å¹³å‡åœ¨èŒå¤©æ•°'], errors='coerce')
    
    # è®¡ç®—DSå æ¯”
    df['DSå æ¯”'] = df['åœ¨èŒäººæ•°'] / df['å‘˜å·¥äººæ•°'] * 100
    
    # ç­›é€‰æœ‰æ•ˆæ•°æ®
    valid_df = df[
        (df['å¹³å‡å¹´æ”¶å…¥'] > 0) & 
        (df['åœ¨èŒäººæ•°'] > 0) & 
        (df['å‘˜å·¥äººæ•°'] > 0) & 
        (df['å¹³å‡åœ¨èŒå¤©æ•°'] > 0) &
        (df['DSå æ¯”'] <= 50)  # æ’é™¤å¼‚å¸¸å€¼
    ].copy()
    
    if len(valid_df) == 0:
        return None, "æ²¡æœ‰æœ‰æ•ˆçš„è¯„åˆ†æ•°æ®"
    
    # 1. è–ªèµ„è¯„åˆ† (0-25åˆ†)
    salary_75 = valid_df['å¹³å‡å¹´æ”¶å…¥'].quantile(0.75)
    salary_25 = valid_df['å¹³å‡å¹´æ”¶å…¥'].quantile(0.25)
    valid_df['è–ªèµ„è¯„åˆ†'] = np.where(
        valid_df['å¹³å‡å¹´æ”¶å…¥'] >= salary_75,
        25,
        np.where(
            valid_df['å¹³å‡å¹´æ”¶å…¥'] >= salary_25,
            15 + (valid_df['å¹³å‡å¹´æ”¶å…¥'] - salary_25) / (salary_75 - salary_25) * 10,
            5 + (valid_df['å¹³å‡å¹´æ”¶å…¥'] - valid_df['å¹³å‡å¹´æ”¶å…¥'].min()) / (salary_25 - valid_df['å¹³å‡å¹´æ”¶å…¥'].min()) * 10
        )
    )
    
    # 2. å…¬å¸è§„æ¨¡è¯„åˆ† (0-20åˆ†)
    valid_df['è§„æ¨¡è¯„åˆ†'] = np.where(
        (valid_df['å‘˜å·¥äººæ•°'] >= 1000) & (valid_df['å‘˜å·¥äººæ•°'] <= 10000),
        20,
        np.where(
            valid_df['å‘˜å·¥äººæ•°'] > 10000,
            15 + 5 * (1 - (valid_df['å‘˜å·¥äººæ•°'] - 10000) / (valid_df['å‘˜å·¥äººæ•°'].max() - 10000)),
            10 + 10 * (valid_df['å‘˜å·¥äººæ•°'] / 1000)
        )
    )
    valid_df['è§„æ¨¡è¯„åˆ†'] = valid_df['è§„æ¨¡è¯„åˆ†'].clip(0, 20)
    
    # 3. å¤´è…°å°¾è¯„åˆ† (0-15åˆ†)
    head_tail_scores = {'å¤´éƒ¨': 15, 'è…°éƒ¨': 10, 'å°¾éƒ¨': 5}
    valid_df['å¤´è…°å°¾è¯„åˆ†'] = valid_df['å¤´è…°å°¾'].map(head_tail_scores).fillna(7.5)
    
    # 4. DSå›¢é˜Ÿè§„æ¨¡è¯„åˆ† (0-15åˆ†)
    ds_team_75 = valid_df['åœ¨èŒäººæ•°'].quantile(0.75)
    ds_team_25 = valid_df['åœ¨èŒäººæ•°'].quantile(0.25)
    valid_df['DSå›¢é˜Ÿè¯„åˆ†'] = np.where(
        valid_df['åœ¨èŒäººæ•°'] >= ds_team_75,
        15,
        np.where(
            valid_df['åœ¨èŒäººæ•°'] >= ds_team_25,
            8 + (valid_df['åœ¨èŒäººæ•°'] - ds_team_25) / (ds_team_75 - ds_team_25) * 7,
            3 + (valid_df['åœ¨èŒäººæ•°'] - valid_df['åœ¨èŒäººæ•°'].min()) / (ds_team_25 - valid_df['åœ¨èŒäººæ•°'].min()) * 5
        )
    )
    
    # 5. DSå æ¯”è¯„åˆ† (0-10åˆ†)
    valid_df['å æ¯”è¯„åˆ†'] = np.where(
        (valid_df['DSå æ¯”'] >= 2) & (valid_df['DSå æ¯”'] <= 8),
        10,
        np.where(
            valid_df['DSå æ¯”'] > 8,
            8 + 2 * (1 - (valid_df['DSå æ¯”'] - 8) / (valid_df['DSå æ¯”'].max() - 8)),
            5 + 5 * (valid_df['DSå æ¯”'] / 2)
        )
    )
    valid_df['å æ¯”è¯„åˆ†'] = valid_df['å æ¯”è¯„åˆ†'].clip(0, 10)
    
    # 6. å·¥ä½œç¨³å®šæ€§è¯„åˆ† (0-15åˆ†)
    days_75 = valid_df['å¹³å‡åœ¨èŒå¤©æ•°'].quantile(0.75)
    days_25 = valid_df['å¹³å‡åœ¨èŒå¤©æ•°'].quantile(0.25)
    valid_df['ç¨³å®šæ€§è¯„åˆ†'] = np.where(
        valid_df['å¹³å‡åœ¨èŒå¤©æ•°'] >= days_75,
        15,
        np.where(
            valid_df['å¹³å‡åœ¨èŒå¤©æ•°'] >= days_25,
            8 + (valid_df['å¹³å‡åœ¨èŒå¤©æ•°'] - days_25) / (days_75 - days_25) * 7,
            3 + (valid_df['å¹³å‡åœ¨èŒå¤©æ•°'] - valid_df['å¹³å‡åœ¨èŒå¤©æ•°'].min()) / (days_25 - valid_df['å¹³å‡åœ¨èŒå¤©æ•°'].min()) * 5
        )
    )
    
    # è®¡ç®—æ€»åˆ†
    valid_df['ç»¼åˆè¯„åˆ†'] = (valid_df['è–ªèµ„è¯„åˆ†'] + valid_df['è§„æ¨¡è¯„åˆ†'] + valid_df['å¤´è…°å°¾è¯„åˆ†'] + 
                           valid_df['DSå›¢é˜Ÿè¯„åˆ†'] + valid_df['å æ¯”è¯„åˆ†'] + valid_df['ç¨³å®šæ€§è¯„åˆ†'])
    
    # ç”Ÿæˆæ’å
    valid_df = valid_df.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).copy()
    valid_df['æ€»æ’å'] = range(1, len(valid_df) + 1)
    valid_df['è¡Œä¸šæ’å'] = valid_df.groupby('è¡Œä¸š')['ç»¼åˆè¯„åˆ†'].rank(ascending=False, method='dense').astype(int)
    
    return valid_df, None

def create_score_analysis(df_scored):
    """åˆ›å»ºè¯„åˆ†åˆ†æå›¾è¡¨"""
    if len(df_scored) == 0:
        return None, "æ²¡æœ‰è¯„åˆ†æ•°æ®"
    
    # å‰100åä¼ä¸š
    top_100 = df_scored.head(100)
    
    # 1. ç»¼åˆè¯„åˆ†åˆ†å¸ƒ
    fig1 = px.histogram(
        top_100, 
        x='ç»¼åˆè¯„åˆ†', 
        nbins=20,
        title='å‰100åä¼ä¸šç»¼åˆè¯„åˆ†åˆ†å¸ƒ',
        labels={'ç»¼åˆè¯„åˆ†': 'ç»¼åˆè¯„åˆ†', 'count': 'ä¼ä¸šæ•°é‡'}
    )
    
    # 2. å„ç»´åº¦è¯„åˆ†åˆ†å¸ƒ
    score_columns = ['è–ªèµ„è¯„åˆ†', 'è§„æ¨¡è¯„åˆ†', 'å¤´è…°å°¾è¯„åˆ†', 'DSå›¢é˜Ÿè¯„åˆ†', 'å æ¯”è¯„åˆ†', 'ç¨³å®šæ€§è¯„åˆ†']
    avg_scores = top_100[score_columns].mean()
    
    fig2 = px.bar(
        x=score_columns,
        y=avg_scores.values,
        title='å‰100åä¼ä¸šå„ç»´åº¦å¹³å‡è¯„åˆ†',
        labels={'x': 'è¯„åˆ†ç»´åº¦', 'y': 'å¹³å‡è¯„åˆ†'},
        color=avg_scores.values,
        color_continuous_scale='viridis'
    )
    fig2.update_xaxes(tickangle=45)
    
    # 3. è¡Œä¸šåˆ†å¸ƒ
    industry_dist = top_100['è¡Œä¸š'].value_counts().head(15)
    fig3 = px.bar(
        x=industry_dist.index,
        y=industry_dist.values,
        title='å‰100åä¼ä¸šè¡Œä¸šåˆ†å¸ƒ',
        labels={'x': 'è¡Œä¸š', 'y': 'ä¼ä¸šæ•°é‡'},
        color=industry_dist.values,
        color_continuous_scale='plasma'
    )
    fig3.update_xaxes(tickangle=45)
    
    # 4. å¤´è…°å°¾åˆ†å¸ƒ
    head_tail_dist = top_100['å¤´è…°å°¾'].value_counts()
    fig4 = px.pie(
        values=head_tail_dist.values,
        names=head_tail_dist.index,
        title='å‰100åä¼ä¸šå¤´è…°å°¾åˆ†å¸ƒ'
    )
    
    # 5. è–ªèµ„vsç»¼åˆè¯„åˆ†æ•£ç‚¹å›¾
    fig5 = px.scatter(
        top_100,
        x='å¹³å‡å¹´æ”¶å…¥',
        y='ç»¼åˆè¯„åˆ†',
        title='è–ªèµ„ä¸ç»¼åˆè¯„åˆ†å…³ç³»',
        labels={'å¹³å‡å¹´æ”¶å…¥': 'å¹³å‡å¹´æ”¶å…¥ï¼ˆå…ƒï¼‰', 'ç»¼åˆè¯„åˆ†': 'ç»¼åˆè¯„åˆ†'},
        hover_data=['å…¬å¸åç§°', 'è¡Œä¸š'],
        color='ç»¼åˆè¯„åˆ†',
        color_continuous_scale='viridis'
    )
    
    # 6. å„è¡Œä¸šå¹³å‡ç»¼åˆè¯„åˆ†
    industry_avg_score = df_scored.groupby('è¡Œä¸š')['ç»¼åˆè¯„åˆ†'].mean().sort_values(ascending=False).head(15)
    fig6 = px.bar(
        x=industry_avg_score.index,
        y=industry_avg_score.values,
        title='å„è¡Œä¸šå¹³å‡ç»¼åˆè¯„åˆ†',
        labels={'x': 'è¡Œä¸š', 'y': 'å¹³å‡ç»¼åˆè¯„åˆ†'},
        color=industry_avg_score.values,
        color_continuous_scale='inferno'
    )
    fig6.update_xaxes(tickangle=45)
    
    return {
        'fig1': fig1,
        'fig2': fig2,
        'fig3': fig3,
        'fig4': fig4,
        'fig5': fig5,
        'fig6': fig6,
        'stats': {
            'total_companies': len(df_scored),
            'top_100_avg_score': top_100['ç»¼åˆè¯„åˆ†'].mean(),
            'top_100_avg_salary': top_100['å¹³å‡å¹´æ”¶å…¥'].mean(),
            'top_100_avg_size': top_100['å‘˜å·¥äººæ•°'].mean(),
            'top_100_avg_team': top_100['åœ¨èŒäººæ•°'].mean(),
            'top_100_avg_ratio': top_100['DSå æ¯”'].mean(),
            'top_100_avg_days': top_100['å¹³å‡åœ¨èŒå¤©æ•°'].mean()
        }
    }, None

def main():
    """ä¸»å‡½æ•°"""
    st.markdown('<h1 class="main-header">ğŸ“Š æ•°æ®åˆ†æå¸ˆå²—ä½ç»¼åˆåˆ†æçœ‹æ¿</h1>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    st.sidebar.header("ğŸ”§ æ•°æ®ç­›é€‰è®¾ç½®")
    
    # æ•°æ®åŠ è½½
    with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
        df = load_data()
    
    if df is None:
        st.error("æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        return
    
    # åŸºæœ¬ä¿¡æ¯
    st.sidebar.markdown("### ğŸ“‹ æ•°æ®æ¦‚è§ˆ")
    st.sidebar.metric("æ€»è®°å½•æ•°", f"{len(df):,}")
    
    # ç­›é€‰æ•°æ®åˆ†æå¸ˆå²—ä½
    ds_df = filter_ds_jobs(df)
    st.sidebar.metric("æ•°æ®åˆ†æå¸ˆå²—ä½", f"{len(ds_df):,}")
    st.sidebar.metric("å æ¯”", f"{len(ds_df)/len(df)*100:.1f}%")
    
    # å¼‚å¸¸å€¼å¤„ç†è®¾ç½®
    st.sidebar.markdown("### ğŸ§¹ å¼‚å¸¸å€¼å¤„ç†")
    remove_outliers = st.sidebar.checkbox("è‡ªåŠ¨å»é™¤å¼‚å¸¸å€¼", value=True)
    outlier_method = st.sidebar.selectbox(
        "å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•",
        ["iqr", "zscore"],
        help="IQR: å››åˆ†ä½è·æ–¹æ³•ï¼ŒZ-score: æ ‡å‡†å·®æ–¹æ³•"
    )
    
    # æ•°æ®ç­›é€‰
    st.sidebar.markdown("### ğŸ¯ æ•°æ®ç­›é€‰")
    
    # è¡Œä¸šç­›é€‰
    industries = sorted(df['è¡Œä¸š'].dropna().unique())
    selected_industries = st.sidebar.multiselect(
        "é€‰æ‹©è¡Œä¸š",
        industries,
        default=industries[:10] if len(industries) > 10 else industries
    )
    
    # åŸå¸‚ç­›é€‰
    cities = sorted(df['åŸå¸‚'].dropna().unique())
    selected_cities = st.sidebar.multiselect(
        "é€‰æ‹©åŸå¸‚",
        cities,
        default=cities[:10] if len(cities) > 10 else cities
    )
    
    # å¤´è…°å°¾ç­›é€‰
    head_tail_options = sorted(df['å¤´è…°å°¾'].dropna().unique())
    selected_head_tail = st.sidebar.multiselect(
        "é€‰æ‹©å¤´è…°å°¾",
        head_tail_options,
        default=head_tail_options
    )
    
    # åº”ç”¨ç­›é€‰
    filtered_df = df.copy()
    if selected_industries:
        filtered_df = filtered_df[filtered_df['è¡Œä¸š'].isin(selected_industries)]
    if selected_cities:
        filtered_df = filtered_df[filtered_df['åŸå¸‚'].isin(selected_cities)]
    if selected_head_tail:
        filtered_df = filtered_df[filtered_df['å¤´è…°å°¾'].isin(selected_head_tail)]
    
    # ç­›é€‰åçš„æ•°æ®åˆ†æå¸ˆå²—ä½
    filtered_ds_df = filter_ds_jobs(filtered_df)
    
    # æ˜¾ç¤ºç­›é€‰ç»“æœ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç­›é€‰åæ€»è®°å½•", f"{len(filtered_df):,}")
    with col2:
        st.metric("ç­›é€‰åDSå²—ä½", f"{len(filtered_ds_df):,}")
    with col3:
        st.metric("DSå²—ä½å æ¯”", f"{len(filtered_ds_df)/len(filtered_df)*100:.1f}%" if len(filtered_df) > 0 else "0%")
    with col4:
        st.metric("ç­›é€‰æ¯”ä¾‹", f"{len(filtered_df)/len(df)*100:.1f}%")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ’° è–ªèµ„åˆ†æ", "ğŸ‘¥ å²—ä½åˆ†å¸ƒ", "ğŸ“Š å‘˜å·¥å æ¯”", "ğŸ† ä¼ä¸šè¯„åˆ†", "ğŸ“ˆ å…¶ä»–ç»´åº¦", "ğŸ“‹ æ•°æ®æ˜ç»†"])
    
    with tab1:
        st.header("ğŸ’° è–ªèµ„åˆ†æ")
        
        if len(filtered_ds_df) > 0:
            salary_analysis, error = create_salary_analysis(filtered_ds_df, remove_outliers)
            
            if error:
                st.warning(error)
            else:
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4, col5, col6 = st.columns(6)
                with col1:
                    st.metric("æœ‰æ•ˆæ•°æ®", f"{salary_analysis['stats']['count']:,}")
                with col2:
                    st.metric("å¹³å‡è–ªèµ„", f"{salary_analysis['stats']['mean']:.1f}")
                with col3:
                    st.metric("ä¸­ä½æ•°", f"{salary_analysis['stats']['median']:.1f}")
                with col4:
                    st.metric("æ ‡å‡†å·®", f"{salary_analysis['stats']['std']:.1f}")
                with col5:
                    st.metric("æœ€ä½è–ªèµ„", f"{salary_analysis['stats']['min']:.1f}")
                with col6:
                    st.metric("æœ€é«˜è–ªèµ„", f"{salary_analysis['stats']['max']:.1f}")
                
                # æ˜¾ç¤ºå›¾è¡¨
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(salary_analysis['fig1'], use_container_width=True)
                with col2:
                    st.plotly_chart(salary_analysis['fig3'], use_container_width=True)
                
                st.plotly_chart(salary_analysis['fig2'], use_container_width=True)
        else:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®åˆ†æå¸ˆå²—ä½æ•°æ®")
    
    with tab2:
        st.header("ğŸ‘¥ å²—ä½åˆ†å¸ƒåˆ†æ")
        
        if len(filtered_ds_df) > 0:
            job_analysis, error = create_job_distribution_analysis(filtered_ds_df, remove_outliers)
            
            if error:
                st.warning(error)
            else:
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("æœ‰æ•ˆæ•°æ®", f"{job_analysis['stats']['count']:,}")
                with col2:
                    st.metric("æ€»å²—ä½äººæ•°", f"{job_analysis['stats']['total_jobs']:,}")
                with col3:
                    st.metric("å¹³å‡å²—ä½äººæ•°", f"{job_analysis['stats']['mean']:.1f}")
                with col4:
                    st.metric("ä¸­ä½æ•°", f"{job_analysis['stats']['median']:.1f}")
                with col5:
                    st.metric("æ ‡å‡†å·®", f"{job_analysis['stats']['std']:.1f}")
                
                # æ˜¾ç¤ºå›¾è¡¨
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(job_analysis['fig1'], use_container_width=True)
                with col2:
                    st.plotly_chart(job_analysis['fig3'], use_container_width=True)
                
                st.plotly_chart(job_analysis['fig2'], use_container_width=True)
        else:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®åˆ†æå¸ˆå²—ä½æ•°æ®")
    
    with tab3:
        st.header("ğŸ“Š å‘˜å·¥å æ¯”åˆ†æ")
        
        if len(filtered_ds_df) > 0:
            ratio_analysis, error = create_employee_ratio_analysis(filtered_ds_df, remove_outliers)
            
            if error:
                st.warning(error)
            else:
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("æœ‰æ•ˆæ•°æ®", f"{ratio_analysis['stats']['count']:,}")
                with col2:
                    st.metric("å¹³å‡å æ¯”", f"{ratio_analysis['stats']['mean_ratio']:.3f}%")
                with col3:
                    st.metric("ä¸­ä½æ•°å æ¯”", f"{ratio_analysis['stats']['median_ratio']:.3f}%")
                with col4:
                    st.metric("æœ€é«˜å æ¯”", f"{ratio_analysis['stats']['max_ratio']:.3f}%")
                with col5:
                    st.metric("æœ€ä½å æ¯”", f"{ratio_analysis['stats']['min_ratio']:.3f}%")
                
                # æ˜¾ç¤ºå›¾è¡¨
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(ratio_analysis['fig1'], use_container_width=True)
                with col2:
                    st.plotly_chart(ratio_analysis['fig2'], use_container_width=True)
                
                st.plotly_chart(ratio_analysis['fig3'], use_container_width=True)
        else:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®åˆ†æå¸ˆå²—ä½æ•°æ®")
    
    with tab4:
        st.header("ğŸ† ä¼ä¸šè¯„åˆ†")
        
        if len(filtered_ds_df) > 0:
            # è®¡ç®—ä¼ä¸šè¯„åˆ†
            df_scored, error = calculate_company_scores(filtered_ds_df)
            
            if error:
                st.warning(error)
            else:
                # æ˜¾ç¤ºè¯„åˆ†åˆ†æ
                score_analysis, error = create_score_analysis(df_scored)
                
                if error:
                    st.warning(error)
                else:
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4, col5, col6 = st.columns(6)
                    with col1:
                        st.metric("æœ‰æ•ˆæ•°æ®", f"{score_analysis['stats']['total_companies']:,}")
                    with col2:
                        st.metric("å‰100åå¹³å‡ç»¼åˆè¯„åˆ†", f"{score_analysis['stats']['top_100_avg_score']:.1f}")
                    with col3:
                        st.metric("å‰100åå¹³å‡è–ªèµ„", f"{score_analysis['stats']['top_100_avg_salary']:.1f}")
                    with col4:
                        st.metric("å‰100åå¹³å‡å…¬å¸è§„æ¨¡", f"{score_analysis['stats']['top_100_avg_size']:.0f}äºº")
                    with col5:
                        st.metric("å‰100åå¹³å‡å›¢é˜Ÿè§„æ¨¡", f"{score_analysis['stats']['top_100_avg_team']:.0f}äºº")
                    with col6:
                        st.metric("å‰100åå¹³å‡DSå æ¯”", f"{score_analysis['stats']['top_100_avg_ratio']:.3f}%")
                    
                    # æ˜¾ç¤ºå›¾è¡¨
                    col1, col2 = st.columns(2)
                    with col1:
                        st.plotly_chart(score_analysis['fig1'], use_container_width=True)
                    with col2:
                        st.plotly_chart(score_analysis['fig2'], use_container_width=True)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.plotly_chart(score_analysis['fig3'], use_container_width=True)
                    with col2:
                        st.plotly_chart(score_analysis['fig4'], use_container_width=True)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.plotly_chart(score_analysis['fig5'], use_container_width=True)
                    with col2:
                        st.plotly_chart(score_analysis['fig6'], use_container_width=True)
                    
                    # ä¼ä¸šæ’åæ¦œå•
                    st.subheader("ğŸ“Š ä¼ä¸šæ’åæ¦œå•")
                    
                    # æ’åç­›é€‰é€‰é¡¹
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        rank_type = st.selectbox(
                            "æ’åç±»å‹",
                            ["æ€»æ’å", "è¡Œä¸šæ’å"],
                            help="é€‰æ‹©æŸ¥çœ‹æ€»æ’åæˆ–è¡Œä¸šæ’å"
                        )
                    with col2:
                        top_n = st.selectbox(
                            "æ˜¾ç¤ºå‰Nå",
                            [10, 20, 50, 100],
                            help="é€‰æ‹©æ˜¾ç¤ºå‰å¤šå°‘åä¼ä¸š"
                        )
                    with col3:
                        selected_industry = st.selectbox(
                            "é€‰æ‹©è¡Œä¸šï¼ˆä»…è¡Œä¸šæ’åæ—¶æœ‰æ•ˆï¼‰",
                            ["å…¨éƒ¨"] + sorted(df_scored['è¡Œä¸š'].unique().tolist()),
                            help="é€‰æ‹©ç‰¹å®šè¡Œä¸šæŸ¥çœ‹æ’å"
                        )
                    
                    # ç­›é€‰æ•°æ®
                    if rank_type == "æ€»æ’å":
                        display_df = df_scored.head(top_n)
                        title = f"ç»¼åˆè¯„åˆ†å‰{top_n}åä¼ä¸š"
                    else:  # è¡Œä¸šæ’å
                        if selected_industry == "å…¨éƒ¨":
                            display_df = df_scored[df_scored['è¡Œä¸šæ’å'] <= top_n].head(top_n * 3)
                            title = f"å„è¡Œä¸šå‰{top_n}åä¼ä¸š"
                        else:
                            industry_df = df_scored[df_scored['è¡Œä¸š'] == selected_industry].copy()
                            display_df = industry_df.head(top_n)
                            title = f"{selected_industry}è¡Œä¸šå‰{top_n}åä¼ä¸š"
                    
                    # æ˜¾ç¤ºæ’åè¡¨æ ¼
                    st.write(f"**{title}**")
                    
                    # é€‰æ‹©æ˜¾ç¤ºçš„åˆ—
                    display_columns = [
                        'æ€»æ’å', 'è¡Œä¸šæ’å', 'å…¬å¸åç§°', 'è¡Œä¸š', 'å¤´è…°å°¾', 
                        'å¹³å‡å¹´æ”¶å…¥', 'å‘˜å·¥äººæ•°', 'åœ¨èŒäººæ•°', 'DSå æ¯”', 
                        'è–ªèµ„è¯„åˆ†', 'è§„æ¨¡è¯„åˆ†', 'å¤´è…°å°¾è¯„åˆ†', 'DSå›¢é˜Ÿè¯„åˆ†', 'å æ¯”è¯„åˆ†', 'ç¨³å®šæ€§è¯„åˆ†', 'ç»¼åˆè¯„åˆ†'
                    ]
                    
                    # æ ¼å¼åŒ–æ•°æ®
                    display_data = display_df[display_columns].copy()
                    display_data['å¹³å‡å¹´æ”¶å…¥'] = display_data['å¹³å‡å¹´æ”¶å…¥'].round(0).astype(int)
                    display_data['å‘˜å·¥äººæ•°'] = display_data['å‘˜å·¥äººæ•°'].round(0).astype(int)
                    display_data['åœ¨èŒäººæ•°'] = display_data['åœ¨èŒäººæ•°'].round(0).astype(int)
                    display_data['DSå æ¯”'] = display_data['DSå æ¯”'].round(3)
                    display_data['ç»¼åˆè¯„åˆ†'] = display_data['ç»¼åˆè¯„åˆ†'].round(2)
                    
                    # é‡å‘½ååˆ—
                    column_mapping = {
                        'æ€»æ’å': 'æ€»æ’å',
                        'è¡Œä¸šæ’å': 'è¡Œä¸šæ’å',
                        'å…¬å¸åç§°': 'å…¬å¸åç§°',
                        'è¡Œä¸š': 'è¡Œä¸š',
                        'å¤´è…°å°¾': 'å¤´è…°å°¾',
                        'å¹³å‡å¹´æ”¶å…¥': 'å¹³å‡å¹´æ”¶å…¥ï¼ˆå…ƒï¼‰',
                        'å‘˜å·¥äººæ•°': 'å‘˜å·¥äººæ•°',
                        'åœ¨èŒäººæ•°': 'åœ¨èŒäººæ•°',
                        'DSå æ¯”': 'DSå æ¯”ï¼ˆ%ï¼‰',
                        'è–ªèµ„è¯„åˆ†': 'è–ªèµ„è¯„åˆ†',
                        'è§„æ¨¡è¯„åˆ†': 'è§„æ¨¡è¯„åˆ†',
                        'å¤´è…°å°¾è¯„åˆ†': 'å¤´è…°å°¾è¯„åˆ†',
                        'DSå›¢é˜Ÿè¯„åˆ†': 'DSå›¢é˜Ÿè¯„åˆ†',
                        'å æ¯”è¯„åˆ†': 'å æ¯”è¯„åˆ†',
                        'ç¨³å®šæ€§è¯„åˆ†': 'ç¨³å®šæ€§è¯„åˆ†',
                        'ç»¼åˆè¯„åˆ†': 'ç»¼åˆè¯„åˆ†'
                    }
                    display_data = display_data.rename(columns=column_mapping)
                    
                    # æ˜¾ç¤ºè¡¨æ ¼
                    st.dataframe(
                        display_data,
                        use_container_width=True,
                        height=400
                    )
                    
                    # ä¸‹è½½æŒ‰é’®
                    csv = display_data.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è½½{title}æ•°æ®",
                        data=csv,
                        file_name=f'{title}_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv'
                    )
                    
                    # è¯„åˆ†ç»´åº¦è¯´æ˜
                    st.subheader("ğŸ“‹ è¯„åˆ†ç»´åº¦è¯´æ˜")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("""
                        **è¯„åˆ†ç»´åº¦æƒé‡ï¼š**
                        - è–ªèµ„è¯„åˆ†ï¼š25åˆ† (25%)
                        - å…¬å¸è§„æ¨¡è¯„åˆ†ï¼š20åˆ† (20%)
                        - å¤´è…°å°¾è¯„åˆ†ï¼š15åˆ† (15%)
                        - DSå›¢é˜Ÿè§„æ¨¡è¯„åˆ†ï¼š15åˆ† (15%)
                        - DSå æ¯”è¯„åˆ†ï¼š10åˆ† (10%)
                        - å·¥ä½œç¨³å®šæ€§è¯„åˆ†ï¼š15åˆ† (15%)
                        - **æ€»åˆ†ï¼š100åˆ†**
                        """)
                    with col2:
                        st.markdown("""
                        **è¯„åˆ†æ ‡å‡†ï¼š**
                        - è–ªèµ„è¯„åˆ†ï¼šåŸºäºè–ªèµ„åˆ†ä½æ•°è®¡ç®—
                        - è§„æ¨¡è¯„åˆ†ï¼š1000-10000äººè§„æ¨¡å¾—åˆ†æœ€é«˜
                        - å¤´è…°å°¾è¯„åˆ†ï¼šå¤´(15åˆ†)ã€è…°(10åˆ†)ã€å°¾(5åˆ†)
                        - DSå›¢é˜Ÿè¯„åˆ†ï¼šåŸºäºå›¢é˜Ÿè§„æ¨¡åˆ†ä½æ•°è®¡ç®—
                        - å æ¯”è¯„åˆ†ï¼š2-8%å æ¯”å¾—åˆ†æœ€é«˜
                        - ç¨³å®šæ€§è¯„åˆ†ï¼šåŸºäºåœ¨èŒå¤©æ•°åˆ†ä½æ•°è®¡ç®—
                        """)
        else:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®åˆ†æå¸ˆå²—ä½æ•°æ®")
    
    with tab5:
        st.header("ğŸ“ˆ å…¶ä»–åˆ†æç»´åº¦")
        
        if len(filtered_ds_df) > 0:
            # å…¬å¸è§„æ¨¡åˆ†æ
            st.subheader("ğŸ¢ å…¬å¸è§„æ¨¡åˆ†æ")
            valid_size = filtered_ds_df[pd.to_numeric(filtered_ds_df['å‘˜å·¥äººæ•°'], errors='coerce') > 0]
            
            if len(valid_size) > 0:
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æœ‰æ•ˆè§„æ¨¡æ•°æ®", f"{len(valid_size):,}")
                with col2:
                    avg_size = valid_size['å‘˜å·¥äººæ•°'].astype(float).mean()
                    st.metric("å¹³å‡å…¬å¸è§„æ¨¡", f"{avg_size:.0f}äºº")
                with col3:
                    median_size = valid_size['å‘˜å·¥äººæ•°'].astype(float).median()
                    st.metric("ä¸­ä½æ•°è§„æ¨¡", f"{median_size:.0f}äºº")
                
                # å…¬å¸è§„æ¨¡åˆ†å¸ƒ
                size_data = valid_size['å‘˜å·¥äººæ•°'].astype(float)
                fig_size = px.histogram(
                    x=size_data,
                    nbins=30,
                    title='å…¬å¸è§„æ¨¡åˆ†å¸ƒ',
                    labels={'x': 'å‘˜å·¥äººæ•°', 'y': 'é¢‘æ¬¡'}
                )
                fig_size.update_xaxes(type="log")
                st.plotly_chart(fig_size, use_container_width=True)
            
            # å¤´è…°å°¾åˆ†å¸ƒ
            st.subheader("ğŸ† å¤´è…°å°¾åˆ†å¸ƒ")
            head_tail_dist = filtered_ds_df['å¤´è…°å°¾'].value_counts()
            fig_head_tail = px.pie(
                values=head_tail_dist.values, 
                names=head_tail_dist.index,
                title='å¤´è…°å°¾åˆ†å¸ƒ'
            )
            st.plotly_chart(fig_head_tail, use_container_width=True)
            
            # åŸå¸‚åˆ†å¸ƒ
            st.subheader("ğŸŒ† åŸå¸‚åˆ†å¸ƒ")
            city_dist = filtered_ds_df['åŸå¸‚'].value_counts()
            fig_city = px.bar(
                x=city_dist.index, 
                y=city_dist.values,
                title='åŸå¸‚åˆ†å¸ƒ',
                labels={'x': 'åŸå¸‚', 'y': 'å²—ä½æ•°é‡'}
            )
            fig_city.update_xaxes(tickangle=45)
            st.plotly_chart(fig_city, use_container_width=True)
        else:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®åˆ†æå¸ˆå²—ä½æ•°æ®")
    
    with tab6:
        st.header("ğŸ“‹ æ•°æ®æ˜ç»†")
        
        if len(filtered_ds_df) > 0:
            # æ•°æ®ä¸‹è½½
            csv = filtered_ds_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç­›é€‰åçš„æ•°æ®",
                data=csv,
                file_name=f'æ•°æ®åˆ†æå¸ˆå²—ä½æ•°æ®_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.csv',
                mime='text/csv'
            )
            
            # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
            st.subheader("æ•°æ®é¢„è§ˆ")
            st.dataframe(
                filtered_ds_df,
                use_container_width=True,
                height=400
            )
            
            # æ•°æ®ç»Ÿè®¡
            st.subheader("æ•°æ®ç»Ÿè®¡")
            st.write(filtered_ds_df.describe())
        else:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®åˆ†æå¸ˆå²—ä½æ•°æ®")

if __name__ == "__main__":
    main() 
